import { promises as fs } from "node:fs";
import { join } from "node:path";
import { EdinetApiClient, type EdinetDocument } from "./edinet-api-client.ts";
import { EdinetNormalizedProcessor } from "./edinet-normalized-processor.ts";
import type { BatchProcessingResult, BatchProcessingError, BatchDocumentRecord, NormalizedResult } from "./normalized-types.ts";

// å›ºå®šè¨­å®šå€¤
const BATCH_CONFIG = {
  target_doc_types: ["120", "130"], // æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸ãƒ»å››åŠæœŸå ±å‘Šæ›¸
  output_directory: "tmp/batch",
};

/**
 * EDINETæ—¥æ¬¡ãƒãƒƒãƒå‡¦ç†ãƒ—ãƒ­ã‚»ãƒƒã‚µ
 */
export class EdinetDailyBatchProcessor {
  private apiClient: EdinetApiClient;
  private normalizedProcessor: EdinetNormalizedProcessor;

  constructor(apiClient: EdinetApiClient, normalizedProcessor: EdinetNormalizedProcessor) {
    this.apiClient = apiClient;
    this.normalizedProcessor = normalizedProcessor;
  }

  /**
   * ãƒ¡ã‚¤ãƒ³ãƒãƒƒãƒå‡¦ç†
   */
  async processDailyBatch(targetDate: string): Promise<BatchProcessingResult> {
    const startTime = Date.now();

    console.log(`ğŸš€ æ—¥æ¬¡ãƒãƒƒãƒå‡¦ç†é–‹å§‹: ${targetDate}`);

    const result: BatchProcessingResult = {
      batch_date: targetDate,
      total_documents: 0,
      target_documents: 0,
      processed_documents: 0,
      failed_documents: 0,
      processing_time_ms: 0,
      documents: [],
      errors: [],
    };

    try {
      // Step 1: æ–‡æ›¸ä¸€è¦§å–å¾—
      console.log("ğŸ“‹ EDINET APIã‹ã‚‰æ–‡æ›¸ä¸€è¦§ã‚’å–å¾—ä¸­...");
      const documentsList = await this.apiClient.fetchDocumentsList(targetDate);

      if (!documentsList.results || documentsList.results.length === 0) {
        console.log("ğŸ“­ å¯¾è±¡æ—¥ä»˜ã«æ–‡æ›¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ");
        result.processing_time_ms = Date.now() - startTime;
        return result;
      }

      result.total_documents = documentsList.results.length;
      console.log(`ğŸ“Š å–å¾—æ–‡æ›¸æ•°: ${result.total_documents}ä»¶`);

      // Step 2: å¯¾è±¡æ–‡æ›¸ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
      console.log("ğŸ” å¯¾è±¡æ–‡æ›¸ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ä¸­...");
      const targetDocuments = this.filterTargetDocuments(documentsList.results);
      result.target_documents = targetDocuments.length;
      console.log(`ğŸ¯ å‡¦ç†å¯¾è±¡æ–‡æ›¸: ${result.target_documents}ä»¶`);

      if (targetDocuments.length === 0) {
        console.log("ğŸ“­ å‡¦ç†å¯¾è±¡ã®æ–‡æ›¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ");
        result.processing_time_ms = Date.now() - startTime;
        return result;
      }

      // Step 3: å„æ–‡æ›¸ã®é †æ¬¡å‡¦ç†
      console.log("âš™ï¸  æ–‡æ›¸å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™...");
      for (let i = 0; i < targetDocuments.length; i++) {
        const document = targetDocuments[i]!;
        const progressInfo = `${i + 1}/${targetDocuments.length}`;

        console.log(`ğŸ“„ [${progressInfo}] å‡¦ç†ä¸­: ${document.docID} (${document.filerName})`);

        try {
          const normalizedResult = await this.processDocument(document);
          const batchDocumentRecord = this.createDocumentRecord(document, normalizedResult, targetDate);

          result.documents.push(batchDocumentRecord);
          result.processed_documents++;

          // å€‹åˆ¥æ–‡æ›¸JSONä¿å­˜
          await this.saveDocumentResult(targetDate, document.docID, normalizedResult);

          console.log(`âœ… [${progressInfo}] å®Œäº†: ${document.docID}`);
        } catch (error) {
          const errorMessage = error instanceof Error ? error.message : String(error);
          const batchError: BatchProcessingError = {
            doc_id: document.docID,
            filer_name: document.filerName,
            error_type: "PROCESSING_ERROR",
            error_message: errorMessage,
            timestamp: new Date().toISOString(),
          };

          result.errors.push(batchError);
          result.failed_documents++;

          console.error(`âŒ [${progressInfo}] ã‚¨ãƒ©ãƒ¼: ${document.docID} - ${errorMessage}`);

          // ã‚¨ãƒ©ãƒ¼æ™‚ã¯å³åº§ã«çµ‚äº†
          throw new Error(`æ–‡æ›¸å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: ${errorMessage}`);
        }
      }

      // Step 4: çµæœä¿å­˜
      await this.saveResults(targetDate, result);

      result.processing_time_ms = Date.now() - startTime;

      console.log("ğŸ‰ ãƒãƒƒãƒå‡¦ç†å®Œäº†!");
      console.log(`ğŸ“ˆ çµ±è¨ˆ: ${result.processed_documents}/${result.target_documents}ä»¶å‡¦ç†å®Œäº† (å‡¦ç†æ™‚é–“: ${result.processing_time_ms}ms)`);

      return result;
    } catch (error) {
      result.processing_time_ms = Date.now() - startTime;

      const errorMessage = error instanceof Error ? error.message : String(error);
      console.error(`ğŸ’¥ ãƒãƒƒãƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: ${errorMessage}`);

      // ãƒ—ãƒ­ã‚»ã‚¹çµ‚äº†ã‚³ãƒ¼ãƒ‰1ã§çµ‚äº†
      process.exit(1);
    }
  }

  /**
   * å¯¾è±¡æ–‡æ›¸ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
   */
  private filterTargetDocuments(documents: EdinetDocument[]): EdinetDocument[] {
    return documents.filter((doc) => {
      // CSVå–å¾—å¯èƒ½ãªæ–‡æ›¸ã®ã¿
      if (doc.csvFlag !== "1") {
        return false;
      }

      // å–ä¸‹ã’æ–‡æ›¸ã¯é™¤å¤–
      if (doc.withdrawalStatus === "1") {
        return false;
      }

      // å¯¾è±¡æ–‡æ›¸ç¨®åˆ¥ï¼ˆæœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸ãƒ»å››åŠæœŸå ±å‘Šæ›¸ï¼‰ã®ã¿
      if (!doc.docTypeCode || !BATCH_CONFIG.target_doc_types.includes(doc.docTypeCode)) {
        return false;
      }

      return true;
    });
  }

  /**
   * å˜ä¸€æ–‡æ›¸å‡¦ç†
   */
  private async processDocument(document: EdinetDocument): Promise<NormalizedResult> {
    try {
      // ZIPå–å¾—
      const zipBuffer = await this.apiClient.fetchDocument(document.docID, "5");

      // æ­£è¦åŒ–å‡¦ç†
      const normalizedResult = await this.normalizedProcessor.processZipToNormalized(Buffer.from(zipBuffer), document.docID);

      return normalizedResult;
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      throw new Error(`æ–‡æ›¸ ${document.docID} ã®å‡¦ç†ã«å¤±æ•—: ${errorMessage}`);
    }
  }

  /**
   * ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿çµ±åˆ
   */
  private createDocumentRecord(edinetDoc: EdinetDocument, normalizedResult: NormalizedResult, targetDate: string): BatchDocumentRecord {
    const baseRecord = normalizedResult.documents[0]!;

    return {
      ...baseRecord,
      // APIæƒ…å ±ã§ä¸Šæ›¸ã
      edinet_code: edinetDoc.edinetCode,
      filer_name: edinetDoc.filerName,
      doc_type: this.mapDocTypeCode(edinetDoc.docTypeCode),
      form_code: edinetDoc.formCode,
      period_start: edinetDoc.periodStart,
      period_end: edinetDoc.periodEnd,
      filed_at_jst: edinetDoc.submitDateTime,
      has_csv: edinetDoc.csvFlag === "1",
      // ãƒãƒƒãƒå‡¦ç†ç”¨è¿½åŠ ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
      seq_number: edinetDoc.seqNumber,
      doc_description: edinetDoc.docDescription,
      batch_date: targetDate,
    };
  }

  /**
   * æ–‡æ›¸ç¨®åˆ¥ã‚³ãƒ¼ãƒ‰ã‚’æ–‡æ›¸ç¨®åˆ¥åã«å¤‰æ›
   */
  private mapDocTypeCode(docTypeCode: string | null): string | null {
    if (!docTypeCode) return null;

    switch (docTypeCode) {
      case "120":
        return "æœ‰ä¾¡è¨¼åˆ¸å ±å‘Šæ›¸";
      case "130":
        return "å››åŠæœŸå ±å‘Šæ›¸";
      default:
        return docTypeCode;
    }
  }

  /**
   * å€‹åˆ¥æ–‡æ›¸çµæœä¿å­˜
   */
  private async saveDocumentResult(targetDate: string, docId: string, normalizedResult: NormalizedResult): Promise<void> {
    const outputDir = join(BATCH_CONFIG.output_directory, targetDate, "documents");
    await fs.mkdir(outputDir, { recursive: true });

    const normalizedJson = await this.normalizedProcessor.exportToJson(normalizedResult);
    const filePath = join(outputDir, `${docId}_normalized.json`);

    await fs.writeFile(filePath, JSON.stringify(normalizedJson, null, 2), "utf-8");
  }

  /**
   * çµæœä¿å­˜
   */
  private async saveResults(targetDate: string, result: BatchProcessingResult): Promise<void> {
    const outputDir = join(BATCH_CONFIG.output_directory, targetDate);
    await fs.mkdir(outputDir, { recursive: true });

    // ãƒãƒƒãƒã‚µãƒãƒªä¿å­˜
    const summaryPath = join(outputDir, "batch_summary.json");
    await fs.writeFile(summaryPath, JSON.stringify(result, null, 2), "utf-8");

    // ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ä¿å­˜ï¼ˆã‚¨ãƒ©ãƒ¼ãŒã‚ã‚‹å ´åˆã®ã¿ï¼‰
    if (result.errors.length > 0) {
      const errorsDir = join(outputDir, "errors");
      await fs.mkdir(errorsDir, { recursive: true });

      const errorsPath = join(errorsDir, "batch_errors.json");
      await fs.writeFile(errorsPath, JSON.stringify(result.errors, null, 2), "utf-8");
    }

    console.log(`ğŸ’¾ ãƒãƒƒãƒçµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: ${outputDir}/`);
  }
}
